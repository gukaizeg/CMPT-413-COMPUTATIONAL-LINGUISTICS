{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bertchunker: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertchunker import *\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:27<00:00, 36.79it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = FinetuneTagger(os.path.join('..', 'data', 'chunker'), modelsuffix='.pt')\n",
    "decoder_output = chunker.decode(os.path.join('..', 'data', 'input', 'dev.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warnings from the transformers library. They are expected to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11952 phrases; correct: 11294.\n",
      "accuracy:  96.70%; (non-O)\n",
      "accuracy:  96.67%; precision:  94.49%; recall:  94.94%; FB1:  94.72\n",
      "             ADJP: precision:  70.97%; recall:  77.88%; FB1:  74.26  248\n",
      "             ADVP: precision:  80.75%; recall:  81.16%; FB1:  80.95  400\n",
      "            CONJP: precision:  50.00%; recall:  71.43%; FB1:  58.82  10\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  95.29%; recall:  95.45%; FB1:  95.37  6247\n",
      "               PP: precision:  97.83%; recall:  97.91%; FB1:  97.87  2443\n",
      "              PRT: precision:  78.72%; recall:  82.22%; FB1:  80.43  47\n",
      "             SBAR: precision:  89.70%; recall:  88.19%; FB1:  88.94  233\n",
      "               VP: precision:  94.71%; recall:  95.53%; FB1:  95.12  2324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94.49464524765729, 94.9394754539341, 94.71653807447164)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "sys.path.append('..')\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('..', 'data', 'reference', 'dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here.\n",
    "\n",
    "Adding noise to the training data so that model can learn these typos\n",
    "```\n",
    "def introduce_spelling_errors(word, error_rate=0.4):\n",
    "    \"\"\"\n",
    "\n",
    "    This function takes a word and introduces a spelling error based on the specified error_rate.\n",
    "    Spelling errors include swapping adjacent letters, inserting a random letter, deleting a random letter,\n",
    "    or replacing a letter with another random letter.\n",
    "\n",
    "    Parameters:\n",
    "    - word (str): The input word to which spelling errors will be introduced.\n",
    "    - error_rate (float): The probability of introducing a spelling error, ranging from 0 to 1.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified word with or without spelling errors.\n",
    "\n",
    "    Example:\n",
    "    >>> introduce_spelling_errors(\"example\")\n",
    "    'examlpe'\n",
    "\n",
    "    >>> introduce_spelling_errors(\"python\", error_rate=0.2)\n",
    "    'pythoon'\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "We also modify the network structure of classification head\n",
    "```\n",
    "nn.Sequential(\n",
    "                nn.Dropout(p=0.1),\n",
    "                nn.Linear(in_features=768, out_features=100, bias=True),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=100, out_features=100, bias=True),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=100, out_features=22, bias=True)\n",
    "                )\n",
    "```\n",
    "\n",
    "Adjusting the learning rate of classification head (5e-4)\n",
    "```\n",
    "encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=lr)\n",
    "classification_head_optimizer = optim.Adam(self.classification_head.parameters(), lr=5e-4)\n",
    "self.optimizers = [encoder_optimizer, classification_head_optimizer]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?\n",
    "\n",
    "* FB1 score has been improved to 94.7165.\n",
    "* There are significant improvements in recall and precision.\n",
    "* Except for INTJ, other categories have significantly improved.\n",
    "\n",
    "\n",
    "Idea (Worked)\n",
    "* Adding noise to the training data so that model can learn these typos\n",
    "* Adding more hidden layers for FFN of classification head\n",
    "\n",
    "Idea (didn't work)\n",
    "* We tried error_rate >= 0.5 to control the generated noise ratio and the FB1 score has been reduced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
