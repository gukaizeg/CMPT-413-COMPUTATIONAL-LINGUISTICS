{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prefixtune: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefixtune import *\n",
    "import os, sys\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the solution on small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = 'distilgpt2'\n",
    "table_to_text = TableToText(\"peft\", basemodel=basemodel)\n",
    "model = AutoModelForCausalLM.from_pretrained(basemodel)\n",
    "decoder_output = table_to_text.decode(model, '../data/input/small.txt')\n",
    "print(\"\\n\".join(decoder_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warnings from the transformers library. They are expected to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `bleu.py`\n",
    "BLEU score has been improved from 0.9 to 30.\n",
    "\n",
    "Prefix Tuning lets the network learn some information from given tables.\n",
    "Since we only have epoch1, the bleu score didn’t improve a lot.\n",
    "\n",
    "We proposed a post-process in this case to make the sentences more reasonable and smooth, which removes repeated phrases at the end of sentences. The score is significantly improved.\n",
    "\n",
    "Score function makes the description highly relevant to the table (many keywords in the given table appeared in generation). The score reached 30.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "We use the peft to implement the prefix tuning.\n",
    "Also we implemented to helper function by ourselves.\n",
    "\n",
    "`def rate_sentence(sentence,target)`: We capture each word from the table and match it to words in the sequence. We score the sequence by the number of successful matches.\n",
    "\n",
    "`def cut_sentence(sentence)`: This is our post-process function. We use it to remove duplicated phrases at the end of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked\n",
    "1  Prefix Tuning\n",
    "\n",
    "The improvement coming from prefix tuning is limited. The reason is we only have one epoch to fine-tune the model, which is not enough to train such a big model. The benefit that prefix tuning gives us is that it allows the model to capture keywords from the table.\n",
    "\n",
    "2  Post-process\n",
    "\n",
    "Since the model wasn’t trained well. So we need a post-process to make our generation smooth and reasonable. The thing we did in post-process is to remove duplicated phrases at the end of sentences.\n",
    "\n",
    "3 Score function\n",
    "\n",
    "We generate more than one sequence and choose the best one as output. We proposed a score function to choose the best one.In our scoring function, we capture each word from the table and match it to words in the sequence. We score the sequence by the number of successful matches.\n",
    "\n",
    "## Didn't work\n",
    "Using gpt2\n",
    "\n",
    "This method didn’t work and even decreased the bleu score. My guess is that it is because gpt2 is larger, so one epoch fine-tune is not enough to let it learn.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
